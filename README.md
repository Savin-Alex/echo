# Echo - AI Copilot with Whisper & Ollama

Echo is a privacy-first AI copilot desktop application built with Electron, React, and FastAPI. It provides real-time transcription, AI-powered summarization, and intelligent assistance using local models.

## ğŸŒŸ Features

### Core Capabilities
- **Real-time Speech Recognition**: Local Whisper ASR with multiple model sizes
- **Local LLM Integration**: Ollama support for privacy-first text generation
- **Context Management**: Vector store with semantic search using ChromaDB
- **OCR Support**: Extract text from images with Tesseract/EasyOCR
- **Voice Analysis**: Audio quality metrics and speech characteristics
- **Privacy-First**: PII redaction, local processing, encrypted storage

### Services
- **ASR**: `/asr/transcribe`, `/asr/transcribe-file`, `/asr/models`, `/asr/status`
- **LLM**: `/llm/summarize`, `/llm/reply`, `/llm/generate`, `/llm/coaching`, `/llm/meeting-notes`
- **Context**: `/context/load`, `/context/search`, `/context/clear`, `/context/load-file`
- **OCR**: `/ocr/extract`, `/ocr/extract-file`
- **Voice**: `/voice/analyze`, `/voice/change`, `/voice/clone`

## ğŸ“‹ Prerequisites

### Required
- **Node.js**: 18+ (for Electron and React)
- **Python**: 3.10+ (for FastAPI backend)
- **Ollama**: Local LLM runtime ([Install from ollama.com](https://ollama.com))

### Optional
- **Tesseract OCR**: For OCR functionality
- **CUDA/ROCm**: For GPU-accelerated inference (faster-whisper)

## ğŸš€ Quick Start

### 1. Install Ollama and Pull a Model

```bash
# macOS/Linux
curl -fsSL https://ollama.com/install.sh | sh

# Windows
# Download from https://ollama.com/download

# Pull a model (llama3 recommended)
ollama pull llama3
```

### 2. Setup Python Backend

```bash
cd python-workers

# Create virtual environment
python -m venv .venv

# Activate virtual environment
# macOS/Linux:
source .venv/bin/activate
# Windows:
.venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### 3. Setup Electron App

```bash
cd electron-app
npm install
```

### 4. Install Root Dependencies

```bash
cd ..  # Back to project root
npm install
```

## ğŸ® Development

### Start Development Environment

From the project root:

```bash
# Start both Python backend and Electron app
npm run dev
```

This will:
1. Start FastAPI backend on `http://127.0.0.1:8000`
2. Start Vite dev server on `http://localhost:5173`
3. Launch Electron with hot reload

### Individual Services

```bash
# Start only Python backend
npm run dev:python

# Start only Electron app
npm run dev:electron
```

### Access API Documentation

While the backend is running, visit:
- Swagger UI: `http://127.0.0.1:8000/docs`
- ReDoc: `http://127.0.0.1:8000/redoc`

## ğŸ—ï¸ Build

### Build for Production

```bash
# Build Python backend
npm run build:python

# Build Electron app
npm run build:electron

# Build everything
npm run build
```

### Create Distributables

```bash
cd electron-app

# macOS
npm run dist

# Windows (cross-compile may require additional setup)
npm run dist

# Linux
npm run dist
```

Distributables will be in `dist/` directory.

## ğŸ§ª Testing

```bash
# Test Python backend
npm run test:python

# Test Electron app
npm run test:electron

# Test everything
npm test
```

## ğŸ“ Project Structure

```
echo/
â”œâ”€â”€ python-workers/              # FastAPI backend
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ main.py              # FastAPI app entry
â”‚   â”‚   â”œâ”€â”€ routes/              # API endpoints
â”‚   â”‚   â”‚   â”œâ”€â”€ asr.py           # Speech recognition
â”‚   â”‚   â”‚   â”œâ”€â”€ llm.py           # LLM operations
â”‚   â”‚   â”‚   â”œâ”€â”€ context.py       # Context management
â”‚   â”‚   â”‚   â”œâ”€â”€ ocr.py           # OCR
â”‚   â”‚   â”‚   â””â”€â”€ voice.py         # Voice processing
â”‚   â”‚   â””â”€â”€ core/                # Business logic
â”‚   â”‚       â”œâ”€â”€ asr_whisper.py   # Whisper integration
â”‚   â”‚       â”œâ”€â”€ llm_router.py    # Ollama client
â”‚   â”‚       â”œâ”€â”€ vectorstore.py   # ChromaDB
â”‚   â”‚       â”œâ”€â”€ embedder.py      # Sentence transformers
â”‚   â”‚       â”œâ”€â”€ ocr_engine.py    # Tesseract/EasyOCR
â”‚   â”‚       â”œâ”€â”€ voice_engine.py  # Audio analysis
â”‚   â”‚       â””â”€â”€ redactor.py      # PII detection
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ electron-app/                # Electron + React
â”‚   â”œâ”€â”€ main/                    # Electron main process
â”‚   â”‚   â”œâ”€â”€ index.ts             # App lifecycle
â”‚   â”‚   â””â”€â”€ ipc/                 # IPC handlers
â”‚   â”œâ”€â”€ preload/                 # Secure bridge
â”‚   â”‚   â””â”€â”€ index.ts
â”‚   â””â”€â”€ renderer/                # React UI
â”‚       â”œâ”€â”€ src/
â”‚       â”‚   â”œâ”€â”€ main.tsx         # React entry
â”‚       â”‚   â”œâ”€â”€ App.tsx          # Root component
â”‚       â”‚   â”œâ”€â”€ pages/           # Page components
â”‚       â”‚   â”œâ”€â”€ components/      # Reusable components
â”‚       â”‚   â””â”€â”€ i18n.ts          # Translations
â”‚       â””â”€â”€ index.html
â”‚
â””â”€â”€ package.json                 # Root workspace config
```

## âš™ï¸ Configuration

### Environment Variables

Create a `.env` file in the project root (or copy `.env.example`):

```bash
# Backend
BACKEND_PORT=8000
BACKEND_HOST=127.0.0.1

# Ollama
OLLAMA_HOST=http://localhost:11434

# Whisper
WHISPER_MODEL=base
WHISPER_DEVICE=cpu

# Embeddings
EMBEDDING_MODEL=all-MiniLM-L6-v2
CHROMA_PERSIST_DIR=./data/chroma

# Privacy
LOCAL_ONLY=true
PII_REDACTION=true
```

### Whisper Models

Available models (size/accuracy trade-off):
- `tiny` - 39 MB, fastest
- `base` - 74 MB, good balance âœ…
- `small` - 244 MB, better accuracy
- `medium` - 769 MB, high accuracy
- `large` - 1550 MB, best accuracy

### Ollama Models

Recommended models:
- `llama3` - Fast and capable âœ…
- `mistral` - Good for reasoning
- `codellama` - Optimized for code
- `phi3` - Very lightweight

Pull models with: `ollama pull <model-name>`

## ğŸ”§ Troubleshooting

### Backend Not Starting

**Issue**: Python backend fails to start

**Solutions**:
```bash
# Check Python version
python --version  # Should be 3.10+

# Recreate virtual environment
cd python-workers
rm -rf .venv
python -m venv .venv
source .venv/bin/activate  # or .venv\Scripts\activate on Windows
pip install -r requirements.txt
```

### Ollama Not Connecting

**Issue**: LLM requests fail with "Ollama not available"

**Solutions**:
```bash
# Check if Ollama is running
curl http://localhost:11434/api/tags

# Start Ollama (if not running)
ollama serve

# Pull a model
ollama pull llama3

# Check models
ollama list
```

### Whisper Not Loading

**Issue**: ASR requests return stub responses

**Solutions**:
```bash
# Install PyTorch with appropriate backend
# CPU-only (smaller):
pip install torch torchaudio --index-url https://download.pytorch.org/whl/cpu

# CUDA (GPU):
pip install torch torchaudio --index-url https://download.pytorch.org/whl/cu118

# Reinstall faster-whisper
pip install --upgrade faster-whisper
```

### Electron Won't Start

**Issue**: Electron fails to launch

**Solutions**:
```bash
# Clean and reinstall
cd electron-app
rm -rf node_modules dist
npm install
npm run build:main

# Check for errors
npm run dev:main
```

## ğŸŒ Internationalization

Echo supports multiple languages:
- English (en)
- Turkish (tr)
- French (fr)

Add more languages in `electron-app/renderer/src/i18n.ts`.

## ğŸ”’ Privacy & Security

- **Local Processing**: All transcription and LLM inference happens on your device
- **PII Redaction**: Automatic detection and masking of sensitive information
- **No Telemetry**: Zero data sent to external servers
- **Encrypted Storage**: Secure credential and data storage
- **Sandboxed Renderer**: Electron security best practices

## ğŸ“ License

ISC License - see LICENSE file

## ğŸ¤ Contributing

Contributions welcome! Please read CONTRIBUTING.md first.

## ğŸ“š Documentation

- [API Documentation](http://127.0.0.1:8000/docs) (when running)
- [Architecture Guide](BUILD.md)
- [Security Improvements](SECURITY_IMPROVEMENTS.md)

## ğŸ¯ Roadmap

- [ ] Real-time audio streaming with WebSocket
- [ ] Advanced OCR with layout analysis
- [ ] Voice cloning integration
- [ ] Multi-language ASR
- [ ] Cloud model fallback (optional)
- [ ] Session recording and replay
- [ ] Advanced analytics dashboard

---

**Made with â¤ï¸ by CriticalSuccess**
